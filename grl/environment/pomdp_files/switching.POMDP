# POMDP file for a slight variation of the "switching actions" POMDP
# mentioned in example 13.1, pg. 323 of Sutton and Barto.
# Here, we have two observations instead of one: one for the start, and one for the other two hallway states.

discount: 0.99999
values: reward
states: 4
actions: 2
observations: 3

start:
1.0 0.0 0.0 0.0

T: 0
0.0 1.0 0.0 0.0
1.0 0.0 0.0 0.0
0.0 0.0 0.0 1.0
0.0 0.0 0.0 1.0

T: 1
1.0 0.0 0.0 0.0
0.0 0.0 1.0 0.0
0.0 1.0 0.0 0.0
0.0 0.0 0.0 1.0


O: *
1.0 0.0 0.0
0.0 1.0 0.0
0.0 1.0 0.0
0.0 0.0 1.0

R: * : * : * : * -1.0
R: * : 3 : 3 : * 0.0

